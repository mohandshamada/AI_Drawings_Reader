#!/bin/bash
# Installation script for PDF Analyzer CLI (Linux/Mac)
# Supports Florence-2 and any Hugging Face vision model
# Uses uv for dependency management

echo "ğŸš€ AI Drawing Analyzer - Installation (Linux/macOS)"
echo "======================================================"
echo ""
echo "This script will help you set up the PDF Analyzer for:"
echo "  âœ… Florence-2 OCR (local, no API key)"
echo "  âœ… Any Hugging Face vision model locally"
echo "  âœ… Cloud APIs (Google Gemini, OpenAI, Anthropic, etc.)"
echo ""

# Check Python version
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 is not installed. Please install Python 3.8 or higher."
    exit 1
fi

PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2)
echo "âœ… Found Python $PYTHON_VERSION"

# Check and install uv if needed
if ! command -v uv &> /dev/null; then
    echo ""
    echo "ğŸ“¦ Installing uv (Python package manager)..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.local/bin:$PATH"
    if ! command -v uv &> /dev/null; then
        echo "âŒ Failed to install uv. Please install manually from https://astral.sh/uv"
        exit 1
    fi
    echo "âœ… uv installed successfully"
else
    echo "âœ… Found uv ($(uv --version))"
fi

# Ask user for installation type
echo ""
echo "Choose your installation type:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "1ï¸âƒ£  LOCAL MODELS ONLY (Recommended)"
echo "   â€¢ Run Florence-2, Qwen-VL, Qwen3-VL, LLaVA locally"
echo "   â€¢ No API key required"
echo "   â€¢ Best for: Technical drawings, blueprints"
echo ""
echo "2ï¸âƒ£  CLOUD APIs ONLY (Minimal)"
echo "   â€¢ Use Gemini, OpenAI, Claude, etc."
echo "   â€¢ Requires API keys"
echo "   â€¢ Best for: Quick testing, occasional use"
echo ""
echo "3ï¸âƒ£  BOTH LOCAL & CLOUD (Full Setup)"
echo "   â€¢ All features: local models + cloud APIs"
echo "   â€¢ Choose which to use at runtime"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
read -p "Enter choice (1-3) [default: 1]: " choice
choice=${choice:-1}

# Install dependencies based on choice
echo ""
echo "ğŸ“¥ Installing dependencies with uv..."
echo "   (This may take 2-5 minutes depending on your internet)"
echo ""

case $choice in
    1)
        echo "ğŸ“š Installing LOCAL MODEL SUPPORT..."
        echo "   â€¢ transformers, torch, timm, einops"
        uv sync --extra local
        echo ""
        echo "ğŸš€ GPU ACCELERATION (Optional but Recommended)"
        echo "   To use GPU (CUDA 11.8) for 10-100x faster inference:"
        echo ""
        echo "   uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
        echo ""
        echo "   For other CUDA versions, visit: https://pytorch.org/get-started/locally/"
        ;;
    2)
        echo "â˜ï¸  Installing CLOUD API SUPPORT..."
        echo "   â€¢ httpx, pymupdf, Pillow, google-auth, etc."
        uv sync
        echo ""
        ;;
    3)
        echo "ğŸ”— Installing FULL SETUP (Local + Cloud)..."
        echo "   â€¢ All local model dependencies"
        echo "   â€¢ All cloud API dependencies"
        uv sync --all-extras
        echo ""
        echo "ğŸš€ GPU ACCELERATION (Optional but Recommended)"
        echo "   To use GPU (CUDA 11.8) for faster inference:"
        echo ""
        echo "   uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
        echo ""
        ;;
    *)
        echo "â“ Invalid choice. Using LOCAL MODELS (option 1) by default..."
        uv sync --extra local
        ;;
esac

# Create .env from example if it doesn't exist
if [ ! -f .env ]; then
    if [ -f .env.example ]; then
        echo ""
        echo "ğŸ“ Creating .env file from template..."
        cp .env.example .env
        if [ "$choice" = "1" ]; then
            echo "âœ… .env file created (not needed for local models)"
        else
            echo "âœ… .env file created. Configure API keys to use cloud providers."
        fi
    fi
fi

echo ""
echo "======================================================"
echo "âœ… Installation Complete!"
echo "======================================================"
echo ""
echo "ğŸ¯ NEXT STEPS:"
echo ""

if [ "$choice" = "1" ]; then
    echo "1ï¸âƒ£  Activate environment:"
    echo "    source .venv/bin/activate"
    echo ""
    echo "2ï¸âƒ£  Test with Florence-2 (interactive):"
    echo "    ai-drawing-analyzer your_document.pdf"
    echo ""
    echo "3ï¸âƒ£  Or use command-line directly:"
    echo "    ai-drawing-analyzer doc.pdf -p huggingface-local -m microsoft/Florence-2-large"
    echo ""
    echo "ğŸ“Š First run will download the model (~2-24GB, takes 5-10 minutes)"
    echo "   Model is cached afterwards for fast reuse"
elif [ "$choice" = "2" ]; then
    echo "1ï¸âƒ£  Activate environment:"
    echo "    source .venv/bin/activate"
    echo ""
    echo "2ï¸âƒ£  Add API keys to .env file:"
    echo "    nano .env"
    echo ""
    echo "3ï¸âƒ£  Test with Gemini (free tier):"
    echo "    ai-drawing-analyzer your_document.pdf -p gemini"
    echo ""
    echo "ğŸ†“ Get free API keys:"
    echo "   â€¢ Google Gemini: https://makersuite.google.com/app/apikey"
    echo "   â€¢ HuggingFace Router: https://huggingface.co/settings/tokens"
else
    echo "1ï¸âƒ£  Activate environment:"
    echo "    source .venv/bin/activate"
    echo ""
    echo "2ï¸âƒ£  Choose your path:"
    echo ""
    echo "   LOCAL (no API key):"
    echo "   ai-drawing-analyzer doc.pdf -p huggingface-local"
    echo ""
    echo "   CLOUD (with API key):"
    echo "   nano .env  (add your API keys)"
    echo "   ai-drawing-analyzer doc.pdf -p gemini"
    echo ""
fi

echo ""
echo "ğŸ“– Documentation:"
echo "   â€¢ Quick Start: QUICK_START.md"
echo "   â€¢ Full Guide: README.md"
echo "   â€¢ Help: ai-drawing-analyzer --help"
echo ""
echo "======================================================"
echo ""
