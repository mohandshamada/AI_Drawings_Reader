@echo off
REM Installation script for PDF Analyzer CLI (Windows)
REM Supports Florence-2 and any Hugging Face vision model
REM Uses uv for dependency management

setlocal enabledelayedexpansion

echo.
echo ğŸš€ AI Drawing Analyzer - Installation (Windows)
echo ======================================================
echo.
echo This script will help you set up the PDF Analyzer for:
echo   âœ… Florence-2 OCR (local, no API key^)
echo   âœ… Any Hugging Face vision model locally
echo   âœ… Cloud APIs (Google Gemini, OpenAI, Anthropic, etc.^)
echo.

REM Check Python installation
python --version >nul 2>&1
if errorlevel 1 (
    echo âŒ Python 3 is not installed or not in PATH
    echo Please install Python 3.8 or higher from python.org
    pause
    exit /b 1
)

echo [OK] Python found:
python --version
echo.

REM Check and install uv if needed
uv --version >nul 2>&1
if errorlevel 1 (
    echo.
    echo ğŸ“¦ Installing uv (Python package manager)...
    powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
    uv --version >nul 2>&1
    if errorlevel 1 (
        echo âŒ Failed to install uv. Please install manually from https://astral.sh/uv
        pause
        exit /b 1
    )
    echo âœ… uv installed successfully
) else (
    for /f "tokens=*" %%i in ('uv --version') do set UV_VERSION=%%i
    echo [OK] Found uv: !UV_VERSION!
)
echo.

REM Ask user for installation type
echo Choose your installation type:
echo â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo 1ï¸âƒ£  LOCAL MODELS ONLY (Recommended^)
echo    â€¢ Run Florence-2, Qwen-VL, Qwen3-VL, LLaVA locally
echo    â€¢ No API key required
echo    â€¢ Best for: Technical drawings, blueprints
echo.
echo 2ï¸âƒ£  CLOUD APIs ONLY (Minimal^)
echo    â€¢ Use Gemini, OpenAI, Claude, etc.
echo    â€¢ Requires API keys
echo    â€¢ Best for: Quick testing, occasional use
echo.
echo 3ï¸âƒ£  BOTH LOCAL and CLOUD (Full Setup^)
echo    â€¢ All features: local models + cloud APIs
echo    â€¢ Choose which to use at runtime
echo â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
set /p choice="Enter choice (1-3, default: 1): "
if "!choice!"=="" set choice=1

REM Install dependencies based on choice using uv
echo.
echo ğŸ“¥ Installing dependencies with uv...
echo    (This may take 2-5 minutes depending on your internet^)
echo.

if "!choice!"=="1" (
    echo ğŸ“š Installing LOCAL MODEL SUPPORT...
    echo    â€¢ transformers, torch, timm, einops
    uv sync --extra local
    echo.
    echo ğŸš€ GPU ACCELERATION (Optional but Recommended^)
    echo    To use GPU (CUDA 11.8^) for 10-100x faster inference:
    echo.
    echo    uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    echo.
    echo    For other CUDA versions, visit: https://pytorch.org/get-started/locally/
    echo.
) else if "!choice!"=="2" (
    echo â˜ï¸  Installing CLOUD API SUPPORT...
    echo    â€¢ httpx, pymupdf, Pillow, google-auth, etc.
    uv sync
    echo.
) else if "!choice!"=="3" (
    echo ğŸ”— Installing FULL SETUP (Local + Cloud^)...
    echo    â€¢ All local model dependencies
    echo    â€¢ All cloud API dependencies
    uv sync --all-extras
    echo.
    echo ğŸš€ GPU ACCELERATION (Optional but Recommended^)
    echo    To use GPU (CUDA 11.8^) for faster inference:
    echo.
    echo    uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    echo.
) else (
    echo â“ Invalid choice. Using LOCAL MODELS (option 1^) by default...
    uv sync --extra local
)

REM Create .env from example if it doesn't exist
if not exist .env (
    echo.
    echo ğŸ“ Creating .env file from template...
    if exist .env.example (
        copy .env.example .env
        if "!choice!"=="1" (
            echo [OK] .env file created (not needed for local models^)
        ) else (
            echo [OK] .env file created. Configure API keys to use cloud providers.
        )
    )
)

echo.
echo ======================================================
echo âœ… Installation Complete!
echo ======================================================
echo.
echo ğŸ¯ NEXT STEPS:
echo.

if "!choice!"=="1" (
    echo 1ï¸âƒ£  Activate environment:
    echo    .venv\Scripts\activate.bat
    echo.
    echo 2ï¸âƒ£  Test with Florence-2 (interactive^):
    echo    ai-drawing-analyzer your_document.pdf
    echo.
    echo 3ï¸âƒ£  Or use command-line directly:
    echo    ai-drawing-analyzer doc.pdf -p huggingface-local -m microsoft/Florence-2-large
    echo.
    echo ğŸ“Š First run will download the model (~2-24GB, takes 5-10 minutes^)
    echo    Model is cached afterwards for fast reuse
) else if "!choice!"=="2" (
    echo 1ï¸âƒ£  Activate environment:
    echo    .venv\Scripts\activate.bat
    echo.
    echo 2ï¸âƒ£  Add API keys to .env file:
    echo    notepad .env
    echo.
    echo 3ï¸âƒ£  Test with Gemini (free tier^):
    echo    ai-drawing-analyzer your_document.pdf -p gemini
    echo.
    echo ğŸ†“ Get free API keys:
    echo    â€¢ Google Gemini: https://makersuite.google.com/app/apikey
    echo    â€¢ HuggingFace Router: https://huggingface.co/settings/tokens
) else (
    echo 1ï¸âƒ£  Activate environment:
    echo    .venv\Scripts\activate.bat
    echo.
    echo 2ï¸âƒ£  Choose your path:
    echo.
    echo    LOCAL (no API key^):
    echo    ai-drawing-analyzer doc.pdf -p huggingface-local
    echo.
    echo    CLOUD (with API key^):
    echo    notepad .env  (add your API keys^)
    echo    ai-drawing-analyzer doc.pdf -p gemini
    echo.
)

echo.
echo ğŸ“– Documentation:
echo    â€¢ Quick Start: QUICK_START.md
echo    â€¢ Full Guide: README.md
echo    â€¢ Help: ai-drawing-analyzer --help
echo.
echo ======================================================
echo.
pause
